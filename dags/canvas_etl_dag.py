# =====================================================
# ğŸ§  Canvas ETL Pipeline (Local API + PostgreSQL DWH)
# Author: VÃµ Trá»ng NghÄ©a (HUTECH)
# =====================================================

from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import requests
import pandas as pd
from sqlalchemy import create_engine
import os
from dotenv import load_dotenv

# --- Load environment variables (.env.local) ---
env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env.local')
if os.path.exists(env_path):
    load_dotenv(env_path)
else:
    load_dotenv()

CANVAS_API_BASE_URL = os.getenv("CANVAS_API_BASE_URL", "http://web/api/v1/")
CANVAS_API_TOKEN = os.getenv("CANVAS_API_TOKEN")
COURSE_IDS = os.getenv("COURSE_IDS", "1,2,3,4").split(",")
DB_CONNECTION_STRING = os.getenv("DB_CONNECTION_STRING")

print(f"ğŸ”§ API URL: {CANVAS_API_BASE_URL}")
print(f"ğŸ”§ Token exists: {bool(CANVAS_API_TOKEN)}")
print(f"ğŸ”§ Course IDs: {COURSE_IDS}")

HEADERS = {"Authorization": f"Bearer {CANVAS_API_TOKEN}"}


# =====================================================
# 1ï¸âƒ£ Extract Courses Info
# =====================================================
def extract_courses():
    courses_data = []

    for cid in COURSE_IDS:
        res = requests.get(f"{CANVAS_API_BASE_URL}courses/{cid}", headers=HEADERS)
        if res.status_code == 200:
            data = res.json()
            courses_data.append({
                "course_id": str(cid),
                "course_name": data.get("name", f"Course {cid}")
            })
            print(f"âœ… Láº¥y thÃ´ng tin khÃ³a há»c: {data.get('name')}")
        else:
            print(f"âš ï¸ KhÃ´ng láº¥y Ä‘Æ°á»£c course {cid} (HTTP {res.status_code})")

    if not courses_data:
        print("âš ï¸ KhÃ´ng cÃ³ khÃ³a há»c nÃ o Ä‘Æ°á»£c láº¥y.")
        return

    df = pd.DataFrame(courses_data)
    engine = create_engine(DB_CONNECTION_STRING)
    df.to_sql("dim_courses", engine, if_exists="replace", index=False)
    print(f"ğŸ“š ÄÃ£ lÆ°u {len(df)} khÃ³a há»c vÃ o báº£ng dim_courses.")


# =====================================================
# 2ï¸âƒ£ Extract Students + Submissions (fix pagination)
# =====================================================
def extract_submissions_data():
    all_students = []
    all_submissions = []

    for course_id in COURSE_IDS:
        print(f"\nğŸ“ Äang xá»­ lÃ½ khÃ³a há»c {course_id}")
        page = 1
        prev_students = None
        total_students = 0

        # --- Láº¥y toÃ n bá»™ sinh viÃªn ---
        while True:
            url = f"{CANVAS_API_BASE_URL}courses/{course_id}/students?per_page=100&page={page}"
            res = requests.get(url, headers=HEADERS)
            if res.status_code != 200:
                print(f"âš ï¸ Lá»—i khi láº¥y sinh viÃªn khÃ³a {course_id}: {res.status_code}")
                break

            students = res.json()
            if not students:
                print(f"âœ… Háº¿t dá»¯ liá»‡u sinh viÃªn sau {page-1} trang.")
                break

            # ğŸš« PhÃ¡t hiá»‡n trÃ¹ng dá»¯ liá»‡u
            if prev_students == students:
                print(f"âš ï¸ PhÃ¡t hiá»‡n dá»¯ liá»‡u láº·p láº¡i á»Ÿ trang {page}, dá»«ng vÃ²ng láº·p.")
                break

            all_students.extend(students)
            total_students += len(students)
            print(f"ğŸ“˜ Trang {page}: {len(students)} sinh viÃªn (Tá»•ng: {total_students})")

            prev_students = students
            page += 1

            if page > 200:
                print("âš ï¸ Dá»«ng vÃ²ng láº·p sau 200 trang Ä‘á»ƒ trÃ¡nh loop vÃ´ háº¡n.")
                break

        # --- Láº¥y danh sÃ¡ch bÃ i táº­p ---
        assign_url = f"{CANVAS_API_BASE_URL}courses/{course_id}/assignments?per_page=100"
        res = requests.get(assign_url, headers=HEADERS)
        if res.status_code != 200:
            print(f"âš ï¸ Lá»—i khi láº¥y assignments khÃ³a {course_id}")
            continue

        assignments = res.json()
        print(f"ğŸ“š {len(assignments)} bÃ i táº­p trong khÃ³a {course_id}")

        # --- Láº¥y bÃ i ná»™p cá»§a tá»«ng assignment ---
        for a in assignments:
            a_id = a["id"]
            sub_page = 1
            prev_subs = None
            while True:
                sub_url = (
                    f"{CANVAS_API_BASE_URL}courses/{course_id}/assignments/{a_id}/submissions"
                    f"?include[]=user&per_page=100&page={sub_page}"
                )
                subs = requests.get(sub_url, headers=HEADERS)
                if subs.status_code != 200:
                    break

                data = subs.json()
                if not data:
                    break

                if prev_subs == data:
                    print(f"âš ï¸ Dá»¯ liá»‡u submissions láº·p láº¡i á»Ÿ trang {sub_page}, dá»«ng.")
                    break

                for s in data:
                    s["course_id"] = str(course_id)
                all_submissions.extend(data)
                print(f"ğŸ“„ {len(data)} submissions (assignment {a_id}, page {sub_page})")

                prev_subs = data
                sub_page += 1

                if sub_page > 200:
                    print("âš ï¸ Dá»«ng láº¥y submissions sau 200 trang.")
                    break

    # --- LÆ°u táº¡m dá»¯ liá»‡u ---
    pd.DataFrame(all_students).to_csv("/tmp/raw_students.csv", index=False)
    pd.DataFrame(all_submissions).to_csv("/tmp/raw_submissions.csv", index=False)
    print(f"ğŸ“¦ HoÃ n táº¥t trÃ­ch xuáº¥t: {len(all_students)} sinh viÃªn, {len(all_submissions)} submissions.")


# =====================================================
# 3ï¸âƒ£ Transform + Load
# =====================================================
def transform_and_load_data():
    students_csv = "/tmp/raw_students.csv"
    submissions_csv = "/tmp/raw_submissions.csv"

    if not os.path.exists(students_csv) or not os.path.exists(submissions_csv):
        print("âš ï¸ Thiáº¿u file dá»¯ liá»‡u thÃ´. HÃ£y cháº¡y task extract trÆ°á»›c.")
        return

    try:
        df_students_raw = pd.read_csv(students_csv)
        df_subs_raw = pd.read_csv(submissions_csv)
    except pd.errors.EmptyDataError:
        print("âš ï¸ File CSV rá»—ng. KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ xá»­ lÃ½.")
        return

    if df_students_raw.empty or df_subs_raw.empty:
        print("âš ï¸ Dá»¯ liá»‡u rá»—ng. KhÃ´ng thá»ƒ tiáº¿p tá»¥c transform.")
        return

    # --- LÃ m sáº¡ch dá»¯ liá»‡u sinh viÃªn ---
    df_students = df_students_raw[["id", "name", "login_id"]].drop_duplicates(subset=["id"])
    df_students.columns = ["student_id", "student_name", "student_email"]

    # --- LÃ m sáº¡ch submissions ---
    cols_needed = ["id", "user.id", "assignment_id", "submitted_at", "grade", "late", "course_id"]
    df_facts = df_subs_raw[[c for c in cols_needed if c in df_subs_raw.columns]].rename(
        columns={"id": "submission_id", "user.id": "student_id"}
    )
    df_facts["submitted_at"] = pd.to_datetime(df_facts["submitted_at"], errors="coerce")
    df_facts["grade"] = pd.to_numeric(df_facts["grade"], errors="coerce")

    # --- Náº¡p vÃ o DB ---
    engine = create_engine(DB_CONNECTION_STRING)
    with engine.connect() as conn:
        df_students.to_sql("dim_students", conn, if_exists="replace", index=False)
        df_facts.to_sql("fact_submissions", conn, if_exists="replace", index=False)

    print(f"ğŸ‘©â€ğŸ“ {len(df_students)} sinh viÃªn â†’ dim_students")
    print(f"ğŸ“Š {len(df_facts)} submissions â†’ fact_submissions")


# =====================================================
# DAG Definition
# =====================================================
with DAG(
    dag_id="canvas_etl_pipeline_local",
    start_date=datetime(2025, 10, 1),
    schedule="@daily",
    catchup=False,
    tags=["canvas", "etl", "local"],
) as dag:

    extract_courses_task = PythonOperator(
        task_id="extract_courses",
        python_callable=extract_courses,
    )

    extract_submissions_task = PythonOperator(
        task_id="extract_submissions_data",
        python_callable=extract_submissions_data,
    )

    transform_and_load_task = PythonOperator(
        task_id="transform_and_load",
        python_callable=transform_and_load_data,
    )

    extract_courses_task >> extract_submissions_task >> transform_and_load_task
